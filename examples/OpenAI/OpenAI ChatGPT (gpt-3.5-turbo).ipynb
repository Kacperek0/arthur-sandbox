{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "794518f6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Arthur Sandbox Example: OpenAI question-answering\n",
    "\n",
    "In this guide, we'll use a question-answering dataset from Huggingface and the ChatGPT endpoint from OpenAI to onboard a new streaming model to the Arthur platform. Then we will use Arthur to analyze our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e524a952",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Outline\n",
    "\n",
    "Read on for an overview of everything this notebook will cover. **[Click here to dive straight into the code.](#Imports)**\n",
    "\n",
    "## Onboarding\n",
    "\n",
    "Onboarding is the process of setting up your model to be monitored by Arthur. You specify the type of data your model ingests, send a reference dataset to provide a baseline of the distribution of your data, and you configure additional settings among the services Arthur offers.\n",
    "\n",
    "**Arthur does not need your model object itself to monitor performance - only predictions are required**\n",
    "\n",
    "All you need to monitor your model with Arthur is to upload the predictions your model makes: Arthur computes analytics about your model based on that prediction data. This data can be computed directly by your model in a script or notebook like this one to be uploaded to the platform, or can be fetched from an external database to be sent to Arthur.\n",
    "\n",
    "### Getting Model Predictions\n",
    "We'll prepare a sample from a question-answering dataset and generate answers from the GPT-3 endpoint.\n",
    "\n",
    "### Registering Model with Arthur\n",
    "We'll configure our model's attributes and save the model to the Arthur platform.\n",
    "\n",
    "### Sending Inferences\n",
    "We'll send model inferences (inputs and predictions) to the Arthur platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6bae60",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ebea11",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fecba162",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ensure required packages are installed\n",
    "#  don't worry, our requirements are flexible!\n",
    "\n",
    "! pip install -r requirements.txt > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e6b33b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T19:08:14.390559Z",
     "start_time": "2021-09-02T19:08:12.824796Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shortuuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61671d47",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9ce8a1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Onboarding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deac8075",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading the Dataset\n",
    "\n",
    "We're using the [SciQ dataset from Huggingface](https://huggingface.co/datasets/sciq)\n",
    "\n",
    "The SciQ dataset contains 13,679 crowdsourced science exam questions about Physics, Chemistry and Biology, among others. The questions are in multiple-choice format with 4 answer options each. For the majority of the questions, an additional paragraph with supporting evidence for the correct answer is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cefa1fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6be9d660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sciq (/Users/maxcembalest/.cache/huggingface/datasets/sciq/default/0.1.0/50e5c6e3795b55463819d399ec417bfd4c3c621105e00295ddb5f3633d708493)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ebc8f5c75a4bf98539fbb61b2588ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sciq_dataset = load_dataset(\"sciq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c71cc7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sciq_df = sciq_dataset.data['train'].table.to_pandas()\n",
    "sciq_df_inf = sciq_dataset.data['test'].table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3408ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sciq_df_sample = sciq_df.sample(50)\n",
    "sciq_df_inf_sample = sciq_df_inf.sample(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585dc8ae",
   "metadata": {},
   "source": [
    "## Create the full LLM inputs by concatenating the actual question after a sentence/paragraph of supporting information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "798a8a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_inputs = [\n",
    "    f\"What is the answer to this question? question: {row.question}, answer: \" \n",
    "    for _, row in sciq_df_sample.iterrows()\n",
    "]\n",
    "\n",
    "chatgpt_inputs_inf = [\n",
    "    f\"What is the answer to this question? question: {row.question}, answer: \" \n",
    "    for _, row in sciq_df_inf_sample.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0cc709",
   "metadata": {},
   "source": [
    "# Get OpenAI responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4433e425",
   "metadata": {},
   "source": [
    "Using the endpoint for the `gpt-3.5-turbo` model, we get an answer to each question from our sample dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3abb0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3793cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def get_chatgpt_responses(\n",
    "    inputs: List[str],\n",
    "    system_config: str = \"You answer scientific questions about physics, biology, and chemistry.\",\n",
    "    example_behavior: Tuple[str, str] = (\"What is the difference between xylem and phloem?\", \"Xylem transports and stores water and water-soluble nutrients in vascular plants. Phloem is responsible for transporting sugars, proteins, and other organic molecules in plants. Vascular plants are able to grow higher than other plants due to the rigidity of xylem cells, which support the plant.\")\n",
    "):\n",
    "    \"\"\"\n",
    "    Applies ChatGPT to the inputs\n",
    "    We manually write a config setting (\"system\" message) and an example back-and-forth (\"user\" and \"assistant\" messages)\n",
    "    \"\"\"\n",
    "    responses = []\n",
    "    for inp in inputs:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_config},\n",
    "            {\"role\": \"user\", \"content\": example_behavior[0]},\n",
    "            {\"role\": \"assistant\", \"content\": example_behavior[1]},\n",
    "            {\"role\": \"user\", \"content\": inp}\n",
    "        ]\n",
    "\n",
    "        openai_response = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages=messages\n",
    "        )\n",
    "        chat_gpt_answer = openai_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        responses.append(openai_response)\n",
    "    \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81ab906a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "responses = get_chatgpt_responses(chatgpt_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73046d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_inf = get_chatgpt_responses(chatgpt_inputs_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9800997",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_texts = [c['choices'][0]['message']['content'] for c in responses]\n",
    "response_texts_inf = [c['choices'][0]['message']['content'] for c in responses_inf]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38872ff",
   "metadata": {},
   "source": [
    "#### Get finish reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f095a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_response_finish_reasons_ref = [c['choices'][0]['finish_reason'] for c in responses]\n",
    "chatgpt_response_finish_reasons_inf = [c['choices'][0]['finish_reason'] for c in responses_inf]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e2b332",
   "metadata": {},
   "source": [
    "#### Get readability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaf3bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat\n",
    "chatgpt_readability_ref = [textstat.flesch_reading_ease(o) for o in response_texts]\n",
    "chatgpt_readability_inf = [textstat.flesch_reading_ease(o) for o in response_texts_inf]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002e9c0",
   "metadata": {},
   "source": [
    "#### Get correctness of answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cea31939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correctness(outputs, answers):\n",
    "    correctnesses = []\n",
    "    for a, o in zip(answers, outputs):\n",
    "        in_ = True\n",
    "        for word in a.replace(',','').split():\n",
    "            if word.lower() not in o.lower():\n",
    "                in_=False\n",
    "        correctnesses.append(in_)\n",
    "    return correctnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "244994b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_correctness_ref = get_correctness(\n",
    "    response_texts,\n",
    "    list(sciq_df_sample.correct_answer.values)\n",
    ")\n",
    "\n",
    "chatgpt_correctness_inf = get_correctness(\n",
    "    response_texts_inf,\n",
    "    list(sciq_df_inf_sample.correct_answer.values)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88b2084",
   "metadata": {},
   "source": [
    "#### Use ChatGPT to get LLM-generated feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "900ef9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pseudofeedback(inputs: List[str]):\n",
    "    responses = []\n",
    "    for inp in inputs:\n",
    "        print(inp)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You give short written feedback saying if an answer made sense for a given question. You also rate the answer out of 10 (0=worst,10=best)\"},\n",
    "            {\"role\": \"user\", \"content\": \"What is the answer to this question? question: What makes breathing difficult due to respiratory system disease?, answer: The answer to this question is the answer to your question.\\n\\nIt is important to know the answer to this question because\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"You didn't actually answer the question, thats bad and confusing. 1\"},\n",
    "            {\"role\": \"user\", \"content\": \"What is the answer to this question? question: What makes breathing difficult due to respiratory system disease?, answer: Respiratory system diseases can make breathing difficult by causing inflammation, damage, or blockages in the airways or lung tissues. These can include conditions such as asthma, chronic obstructive pulmonary disease (COPD), pneumonia, lung cancer, and others. The inflammation and swelling can narrow the airways, making it harder for air to flow in and out of the lungs. Damage to the lung tissues can reduce their ability to expand and contract, which can also make breathing difficult. Additionally, excess mucus or fluid in the lungs can further narrow the airways and make it hard to breathe. These factors can cause symptoms such as shortness of breath, coughing, wheezing, and fatigue.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Thank you very much, that makes a lot of sense! 10\"},\n",
    "            {\"role\": \"user\", \"content\": inp}\n",
    "        ]\n",
    "\n",
    "        openai_response = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages=messages\n",
    "        )\n",
    "        chat_gpt_answer = openai_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        print(chat_gpt_answer, \"\\n=====\\n\")\n",
    "        responses.append(openai_response)\n",
    "    \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "821cd871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the answer to this question? question: How often does condensation occur in your cells?, answer: Condensation frequently occurs within cells during various cellular activities such as respiration, metabolism, energy production, protein synthesis, and DNA replication. However, the exact frequency of condensation occurring within cells would depend on the specific cellular activity taking place and the environmental conditions of the cell.\n",
      "The answer is clear and provides relevant information to the question. Well done! 9 \n",
      "=====\n",
      "\n",
      "What is the answer to this question? question: The e. coli chromosome, like many other bacterial chromosomes, is what shape?, answer: The E. coli chromosome, like many other bacterial chromosomes, is circular in shape.\n",
      "Your answer is very clear and accurate. It makes sense for the given question. 10. \n",
      "=====\n",
      "\n",
      "What is the answer to this question? question: Which members of the food chain break down remains of plants and other organisms when they die?, answer: The members of the food chain that break down remains of plants and other organisms when they die are known as decomposers. Examples of decomposers include bacteria, fungi, and detritivores. These organisms play an important role in the ecosystem by breaking down dead organic matter into simpler compounds, which are then used by plants and other organisms as nutrients.\n",
      "Great answer, it is clear and directly addresses the question. 10 \n",
      "=====\n",
      "\n",
      "What is the answer to this question? question: What do you call mixtures of ash and water that travel down river valleys?, answer: The answer to this question is \"lahar\". A lahar is a mixture of volcanic ash and water that travels down the slopes of a volcano and can quickly flow down river valleys, causing dangerous mudflows.\n",
      "Excellent answer, that is absolutely correct and explained well! 10 \n",
      "=====\n",
      "\n",
      "What is the answer to this question? question: Organic substances, including proteins, carbohydrates, and oils, contain what element?, answer: The element that organic substances, including proteins, carbohydrates, and oils, contain is Carbon (C).\n",
      "Your answer is correct and makes sense. 10 \n",
      "=====\n",
      "\n",
      "What is the answer to this question? question: A rock that contains important minerals is called what, a term associated with mining?, answer: The term associated with mining for a rock that contains important minerals is called an ore.\n",
      "Yes, that answer makes sense in the context of the question. Well done! 10. \n",
      "=====\n",
      "\n",
      "What is the answer to this question? question: What happens when mammals raise their hair with tiny muscles in the skin?, answer: When mammals raise their hair with tiny muscles in the skin, it is called piloerection or \"goosebumps.\" This response is triggered by the sympathetic nervous system in response to various stimuli, such as fear, cold, or strong emotions. The raised hair helps trap a layer of air, which can provide insulation and help keep the animal warm, or serve as a defensive mechanism to make the animal appear larger and more intimidating to predators. In humans, the piloerection response is less pronounced and serves mainly as a vestigial function.\n",
      "Great answer, it is clear and informative. 10 \n",
      "=====\n",
      "\n",
      "What is the answer to this question? question: The pressure inside a container is dependent on the amount of what inside the container?, answer: The pressure inside a container is dependent on the amount of gas (or air) inside the container. This is because as gas particles collide with the walls of the container, they exert a force that creates the pressure inside the container. The greater the number of gas particles in the container, the greater the frequency of particle collisions and hence, the greater the pressure. Additionally, the volume of the container, temperature, and the type of gas can also affect the pressure inside the container.\n",
      "Great answer, it is clear and accurate. 10 \n",
      "=====\n",
      "\n",
      "What is the answer to this question? question: In an aqueous solution, what is the solvent?, answer: In an aqueous solution, the solvent is water.\n",
      "Yes, that's correct and concise. Good job! 9 \n",
      "=====\n",
      "\n",
      "What is the answer to this question? question: What refers to the ability to change or move matter and is required by all life processes and living things?, answer: The answer is \"energy.\" Energy is required by all life processes and living things to change or move matter.\n",
      "Yes, that answer makes perfect sense! 10 \n",
      "=====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chatgpt_pseudofeedback_ref = get_pseudofeedback([inp + rt for inp, rt in zip(chatgpt_inputs, response_texts)])\n",
    "chatgpt_pseudofeedback_inf = get_pseudofeedback([inp + rt for inp, rt in zip(chatgpt_inputs_inf, response_texts_inf)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4819c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feedback_scores(feedback_strings):\n",
    "    feedback_ints = []\n",
    "    for fs in feedback_strings:\n",
    "        score = -1\n",
    "        fs = fs.replace('out of 10', '')\n",
    "        for num_string in np.arange(11).astype(str):\n",
    "            if num_string in fs:\n",
    "                score = int(num_string)\n",
    "        feedback_ints.append(score)\n",
    "    return feedback_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8343ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudofeedback_messages_ref = [c['choices'][0]['message']['content'] for c in chatgpt_pseudofeedback_ref]\n",
    "pseudofeedback_messages_inf = [c['choices'][0]['message']['content'] for c in chatgpt_pseudofeedback_inf]\n",
    "\n",
    "feedback_scores_ref = get_feedback_scores(pseudofeedback_messages_ref)\n",
    "feedback_scores_inf = get_feedback_scores(pseudofeedback_messages_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f9c1d4",
   "metadata": {},
   "source": [
    "### Create inference dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "690a2178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>output_text</th>\n",
       "      <th>finish_reason</th>\n",
       "      <th>readability</th>\n",
       "      <th>correct</th>\n",
       "      <th>user_feedback</th>\n",
       "      <th>user_feedback_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the answer to this question? question:...</td>\n",
       "      <td>Condensation frequently occurs within cells du...</td>\n",
       "      <td>stop</td>\n",
       "      <td>-2.13</td>\n",
       "      <td>False</td>\n",
       "      <td>The answer is clear and provides relevant info...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the answer to this question? question:...</td>\n",
       "      <td>The E. coli chromosome, like many other bacter...</td>\n",
       "      <td>stop</td>\n",
       "      <td>41.36</td>\n",
       "      <td>True</td>\n",
       "      <td>Your answer is very clear and accurate. It mak...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the answer to this question? question:...</td>\n",
       "      <td>The members of the food chain that break down ...</td>\n",
       "      <td>stop</td>\n",
       "      <td>51.48</td>\n",
       "      <td>True</td>\n",
       "      <td>Great answer, it is clear and directly address...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the answer to this question? question:...</td>\n",
       "      <td>The answer to this question is \"lahar\". A laha...</td>\n",
       "      <td>stop</td>\n",
       "      <td>62.17</td>\n",
       "      <td>False</td>\n",
       "      <td>Excellent answer, that is absolutely correct a...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the answer to this question? question:...</td>\n",
       "      <td>The element that organic substances, including...</td>\n",
       "      <td>stop</td>\n",
       "      <td>31.89</td>\n",
       "      <td>True</td>\n",
       "      <td>Your answer is correct and makes sense. 10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What is the answer to this question? question:...   \n",
       "1  What is the answer to this question? question:...   \n",
       "2  What is the answer to this question? question:...   \n",
       "3  What is the answer to this question? question:...   \n",
       "4  What is the answer to this question? question:...   \n",
       "\n",
       "                                         output_text finish_reason  \\\n",
       "0  Condensation frequently occurs within cells du...          stop   \n",
       "1  The E. coli chromosome, like many other bacter...          stop   \n",
       "2  The members of the food chain that break down ...          stop   \n",
       "3  The answer to this question is \"lahar\". A laha...          stop   \n",
       "4  The element that organic substances, including...          stop   \n",
       "\n",
       "   readability  correct                                      user_feedback  \\\n",
       "0        -2.13    False  The answer is clear and provides relevant info...   \n",
       "1        41.36     True  Your answer is very clear and accurate. It mak...   \n",
       "2        51.48     True  Great answer, it is clear and directly address...   \n",
       "3        62.17    False  Excellent answer, that is absolutely correct a...   \n",
       "4        31.89     True         Your answer is correct and makes sense. 10   \n",
       "\n",
       "   user_feedback_score  \n",
       "0                    9  \n",
       "1                   10  \n",
       "2                   10  \n",
       "3                   10  \n",
       "4                   10  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_ref_data = pd.DataFrame({\n",
    "    'user_input':chatgpt_inputs,\n",
    "    'output_text':response_texts,\n",
    "    'finish_reason':chatgpt_response_finish_reasons_ref,\n",
    "    'readability':chatgpt_readability_ref,\n",
    "    'correct':chatgpt_correctness_ref,\n",
    "    'user_feedback':pseudofeedback_messages_ref,\n",
    "    'user_feedback_score':feedback_scores_ref,\n",
    "})\n",
    "chatgpt_ref_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "889f6138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>output_text</th>\n",
       "      <th>finish_reason</th>\n",
       "      <th>readability</th>\n",
       "      <th>correct</th>\n",
       "      <th>user_feedback</th>\n",
       "      <th>user_feedback_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the answer to this question? question:...</td>\n",
       "      <td>The term associated with mining for a rock tha...</td>\n",
       "      <td>stop</td>\n",
       "      <td>55.24</td>\n",
       "      <td>True</td>\n",
       "      <td>Yes, that answer makes sense in the context of...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the answer to this question? question:...</td>\n",
       "      <td>When mammals raise their hair with tiny muscle...</td>\n",
       "      <td>stop</td>\n",
       "      <td>57.30</td>\n",
       "      <td>True</td>\n",
       "      <td>Great answer, it is clear and informative. 10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the answer to this question? question:...</td>\n",
       "      <td>The pressure inside a container is dependent o...</td>\n",
       "      <td>stop</td>\n",
       "      <td>50.16</td>\n",
       "      <td>True</td>\n",
       "      <td>Great answer, it is clear and accurate. 10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the answer to this question? question:...</td>\n",
       "      <td>In an aqueous solution, the solvent is water.</td>\n",
       "      <td>stop</td>\n",
       "      <td>63.36</td>\n",
       "      <td>True</td>\n",
       "      <td>Yes, that's correct and concise. Good job! 9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the answer to this question? question:...</td>\n",
       "      <td>The answer is \"energy.\" Energy is required by ...</td>\n",
       "      <td>stop</td>\n",
       "      <td>70.29</td>\n",
       "      <td>True</td>\n",
       "      <td>Yes, that answer makes perfect sense! 10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What is the answer to this question? question:...   \n",
       "1  What is the answer to this question? question:...   \n",
       "2  What is the answer to this question? question:...   \n",
       "3  What is the answer to this question? question:...   \n",
       "4  What is the answer to this question? question:...   \n",
       "\n",
       "                                         output_text finish_reason  \\\n",
       "0  The term associated with mining for a rock tha...          stop   \n",
       "1  When mammals raise their hair with tiny muscle...          stop   \n",
       "2  The pressure inside a container is dependent o...          stop   \n",
       "3      In an aqueous solution, the solvent is water.          stop   \n",
       "4  The answer is \"energy.\" Energy is required by ...          stop   \n",
       "\n",
       "   readability  correct                                      user_feedback  \\\n",
       "0        55.24     True  Yes, that answer makes sense in the context of...   \n",
       "1        57.30     True      Great answer, it is clear and informative. 10   \n",
       "2        50.16     True         Great answer, it is clear and accurate. 10   \n",
       "3        63.36     True       Yes, that's correct and concise. Good job! 9   \n",
       "4        70.29     True           Yes, that answer makes perfect sense! 10   \n",
       "\n",
       "   user_feedback_score  \n",
       "0                   10  \n",
       "1                   10  \n",
       "2                   10  \n",
       "3                    9  \n",
       "4                   10  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_inf_data = pd.DataFrame({\n",
    "    'user_input':chatgpt_inputs,\n",
    "    'output_text':response_texts_inf,\n",
    "    'finish_reason':chatgpt_response_finish_reasons_inf,\n",
    "    'readability':chatgpt_readability_inf,\n",
    "    'correct':chatgpt_correctness_inf,\n",
    "    'user_feedback':pseudofeedback_messages_inf,\n",
    "    'user_feedback_score':feedback_scores_inf,\n",
    "})\n",
    "chatgpt_inf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c670af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatgpt_ref_data.to_csv('chatgpt_reference_data.csv')\n",
    "# chatgpt_inf_data.to_csv('chatgpt_inference_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bacde00",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Registering Model With Arthur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8204e0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setting Up Connection\n",
    "Supply your login to authenticate with the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d0ffb32",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter password for admin: ········\n"
     ]
    }
   ],
   "source": [
    "from arthurai import ArthurAI\n",
    "# connect to Arthur\n",
    "\n",
    "arthur = ArthurAI(\n",
    "    url=\"https://app.arthur.ai\",  # you can also pass this through the ARTHUR_ENDPOINT_URL environment variable\n",
    "    login=\"<your login here>\",  # you can also pass this through the ARTHUR_LOGIN environment variable\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f45cba",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Registering Model Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce5ac65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arthurai.common.constants import InputType, OutputType, ValueType, Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976dac6d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We'll instantiate an [`ArthurModel`](https://docs.arthur.ai/sdk/sdk_v3/apiref/arthurai.core.models.ArthurModel.html) with the `ArthurAI.model()` method, which constructs a new local `ArthurModel` object. Later we'll use `ArthurModel.save()` to register this model with the Arthur platform.\n",
    "\n",
    "We give the model a user-friendly `display_name` and allow the unique `partner_model_id` field to be automatically generated, but you can supply a unique identifier if it helps you map your models in Arthur to your other MLOps systems.\n",
    "\n",
    "The `InputType` of a model specifies the general type of data your model ingests. The `OutputType` of a model specifies the modeling task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b60f099",
   "metadata": {},
   "source": [
    "### Building the model by specifying attributes\n",
    "\n",
    "We use a helper function to register the model attributes for the input and output text the model will process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c7c14b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T19:08:20.533507Z",
     "start_time": "2021-09-02T19:08:20.531272Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>stage</th>\n",
       "      <th>value_type</th>\n",
       "      <th>categorical</th>\n",
       "      <th>is_unique</th>\n",
       "      <th>categories</th>\n",
       "      <th>bins</th>\n",
       "      <th>range</th>\n",
       "      <th>monitor_for_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_input</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>UNSTRUCTURED_TEXT</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>output_text</td>\n",
       "      <td>PREDICTED_VALUE</td>\n",
       "      <td>UNSTRUCTURED_TEXT</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>finish_reason</td>\n",
       "      <td>NON_INPUT_DATA</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: length}, {value: stop}]</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>readability</td>\n",
       "      <td>NON_INPUT_DATA</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 100]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>correct</td>\n",
       "      <td>NON_INPUT_DATA</td>\n",
       "      <td>BOOLEAN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: True}, {value: False}]</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>user_feedback</td>\n",
       "      <td>NON_INPUT_DATA</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>user_feedback_score</td>\n",
       "      <td>NON_INPUT_DATA</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: -1}, {value: 0}, {value: 1}, {value: ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name            stage         value_type categorical  \\\n",
       "0           user_input   PIPELINE_INPUT  UNSTRUCTURED_TEXT        True   \n",
       "1          output_text  PREDICTED_VALUE  UNSTRUCTURED_TEXT        True   \n",
       "2        finish_reason   NON_INPUT_DATA             STRING        True   \n",
       "3          readability   NON_INPUT_DATA              FLOAT       False   \n",
       "4              correct   NON_INPUT_DATA            BOOLEAN        True   \n",
       "5        user_feedback   NON_INPUT_DATA             STRING        True   \n",
       "6  user_feedback_score   NON_INPUT_DATA            INTEGER        True   \n",
       "\n",
       "  is_unique                                         categories  bins  \\\n",
       "0      True                                                 []  None   \n",
       "1     False                                                 []  None   \n",
       "2     False                   [{value: length}, {value: stop}]  None   \n",
       "3     False                                                 []  None   \n",
       "4     False                    [{value: True}, {value: False}]  None   \n",
       "5      True                                                 []  None   \n",
       "6     False  [{value: -1}, {value: 0}, {value: 1}, {value: ...  None   \n",
       "\n",
       "          range monitor_for_bias  \n",
       "0  [None, None]            False  \n",
       "1  [None, None]            False  \n",
       "2  [None, None]            False  \n",
       "3      [0, 100]            False  \n",
       "4  [None, None]            False  \n",
       "5  [None, None]            False  \n",
       "6  [None, None]            False  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register arthur model type\n",
    "arthur_model_chatgpt = arthur.model(\n",
    "    display_name=\"OpenAI_ChatGPT\",\n",
    "    input_type=InputType.NLP, \n",
    "    output_type=OutputType.TokenSequence)\n",
    "\n",
    "# register attributes for token sequence model\n",
    "arthur_model_chatgpt.build_token_sequence_model(\n",
    "    input_column=\"user_input\", \n",
    "    output_text_column=\"output_text\"\n",
    ")\n",
    "\n",
    "# register additional non-input attributes\n",
    "arthur_model_chatgpt.add_attribute(\n",
    "    name='finish_reason', \n",
    "    stage=Stage.NonInputData,\n",
    "    value_type=ValueType.String,\n",
    "    categorical=True,\n",
    "    categories=['length', 'stop']\n",
    ")\n",
    "\n",
    "arthur_model_chatgpt.add_attribute(\n",
    "    name=\"readability\",\n",
    "    stage=Stage.NonInputData,\n",
    "    value_type=ValueType.Float,\n",
    "    min_range=0,\n",
    "    max_range=100\n",
    ")\n",
    "\n",
    "arthur_model_chatgpt.add_attribute(\n",
    "    name=\"correct\",\n",
    "    stage=Stage.NonInputData,\n",
    "    value_type=ValueType.Boolean,\n",
    "    categorical=True,\n",
    "    categories=[True,False]\n",
    ")\n",
    "\n",
    "arthur_model_chatgpt.add_attribute(\n",
    "    name=\"user_feedback\",\n",
    "    stage=Stage.NonInputData,\n",
    "    value_type=ValueType.String,\n",
    "    categorical=True,\n",
    "    is_unique=True\n",
    ")\n",
    "\n",
    "arthur_model_chatgpt.add_attribute(\n",
    "    name=\"user_feedback_score\",\n",
    "    stage=Stage.NonInputData,\n",
    "    value_type=ValueType.Integer,\n",
    "    categorical=True,\n",
    "    categories=[-1,0,1,2,3,4,5,6,7,8,9,10]\n",
    ")\n",
    "\n",
    "arthur_model_chatgpt.review()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0290514d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f0ec2b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Before saving, be sure to review your model to make sure everything is correct. We already saw the model schema returned by `ArthurModel.build()`, but we have since changed our attribute congiruations. Therefore we call `ArthurModel.review()` to see that our changed attributes look correct before saving to the platform. See the [onboarding walkthrough on the Arthur docs](https://docs.arthur.ai/user-guide/walkthroughs/model-onboarding/index.html#review-model) for tips on reviewing your model.\n",
    "\n",
    "Note that while we capture the ranges of the attributes in this schema, they don’t need to be exact and won’t affect any performance calculations. They’re used as metadata to configure plots in the online Arthur dashboard, but never affect data drift or any other computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f77b552b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>stage</th>\n",
       "      <th>value_type</th>\n",
       "      <th>categorical</th>\n",
       "      <th>is_unique</th>\n",
       "      <th>categories</th>\n",
       "      <th>bins</th>\n",
       "      <th>range</th>\n",
       "      <th>monitor_for_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_input</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>UNSTRUCTURED_TEXT</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>output_text</td>\n",
       "      <td>PREDICTED_VALUE</td>\n",
       "      <td>UNSTRUCTURED_TEXT</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>finish_reason</td>\n",
       "      <td>NON_INPUT_DATA</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: length}, {value: stop}]</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>readability</td>\n",
       "      <td>NON_INPUT_DATA</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 100]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>correct</td>\n",
       "      <td>NON_INPUT_DATA</td>\n",
       "      <td>BOOLEAN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: True}, {value: False}]</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>user_feedback</td>\n",
       "      <td>NON_INPUT_DATA</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>user_feedback_score</td>\n",
       "      <td>NON_INPUT_DATA</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: -1}, {value: 0}, {value: 1}, {value: ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name            stage         value_type categorical  \\\n",
       "0           user_input   PIPELINE_INPUT  UNSTRUCTURED_TEXT        True   \n",
       "1          output_text  PREDICTED_VALUE  UNSTRUCTURED_TEXT        True   \n",
       "2        finish_reason   NON_INPUT_DATA             STRING        True   \n",
       "3          readability   NON_INPUT_DATA              FLOAT       False   \n",
       "4              correct   NON_INPUT_DATA            BOOLEAN        True   \n",
       "5        user_feedback   NON_INPUT_DATA             STRING        True   \n",
       "6  user_feedback_score   NON_INPUT_DATA            INTEGER        True   \n",
       "\n",
       "  is_unique                                         categories  bins  \\\n",
       "0      True                                                 []  None   \n",
       "1     False                                                 []  None   \n",
       "2     False                   [{value: length}, {value: stop}]  None   \n",
       "3     False                                                 []  None   \n",
       "4     False                    [{value: True}, {value: False}]  None   \n",
       "5      True                                                 []  None   \n",
       "6     False  [{value: -1}, {value: 0}, {value: 1}, {value: ...  None   \n",
       "\n",
       "          range monitor_for_bias  \n",
       "0  [None, None]            False  \n",
       "1  [None, None]            False  \n",
       "2  [None, None]            False  \n",
       "3      [0, 100]            False  \n",
       "4  [None, None]            False  \n",
       "5  [None, None]            False  \n",
       "6  [None, None]            False  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# review the model attribute properties in the model schema\n",
    "arthur_model_chatgpt.review()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b295dc3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, we save the model. \n",
    "\n",
    "Note that this will be the first call to send data to the Arthur platform so far in this example - no information has been sent yet to the platform.\n",
    "\n",
    "The method `ArthurModel.save()` sends an API request to Arthur to validate your model - if there are any problems with your model schema, this method will result in an error informing you how to correct your model's configuration. If no errors are found, the model will be saved to the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e956292f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:46:15 - arthurai - We have registered the  model with Arthur and are getting it ready to accept inferences...\n",
      "10:47:01 - arthurai - Model Creation Completed successfully, you can now send Data to Arthur.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'113fbaf0-5749-47a2-94da-63d93077d520'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate the model and save it onto the Arthur platform\n",
    "arthur_model_chatgpt.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73d5e474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:25:21 - arthurai - Starting upload (0.005 MB in 1 files), depending on data size this may take a few minutes\n",
      "18:25:21 - arthurai - Upload completed: /var/folders/8v/8v36mrp907z7lp5d4cd7yf4h0000gn/T/tmpmd5plux2/aea149ea-aef1-43e3-9acc-de15e81be501-0.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'counts': {'success': 50, 'failure': 0, 'total': 50}, 'failures': [[]]},\n",
       " {'dataset_close_result': {'message': 'success'}})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arthur_model_chatgpt.set_reference_data(data=chatgpt_ref_data['user_input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7464bea3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='sending_inferences_content'></a>\n",
    "\n",
    "## Sending Inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e669b6d2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Using `ArthurModel.send_inferences()`\n",
    "\n",
    "We send our inference data to the platform along with some unique IDs. Timestamps will be auto-generated for these inferences by the `send_inferences` function from the Arthur SDK. See [our API docs for sending inferences](https://docs.arthur.ai/api-documentation/v3-api-docs.html#tag/inferences/paths/~1models~1%7Bmodel_id%7D~1inferences/post) for the full specification of inference ingestion in Arthur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bc2763e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:47:29 - arthurai - 5 rows were missing inference_timestamp fields, so the current time was populated\n",
      "# of successful and # of failing inference uploads: {'failure': 0, 'success': 5, 'total': 5}\n"
     ]
    }
   ],
   "source": [
    "inference_result = arthur_model_chatgpt.send_inferences(\n",
    "    chatgpt_inf_data, \n",
    "    partner_inference_ids=[shortuuid.uuid() for _ in range(len(chatgpt_inputs_inf))])\n",
    "print('# of successful and # of failing inference uploads:', inference_result['counts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd79eccc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## See Model in Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9899c692",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br> <a style=\"font-size:200%\" href=https://dev.arthur.ai/model/aea149ea-aef1-43e3-9acc-de15e81be501/overview>See your model (OpenAI_ChatGPT) in the Arthur Dashboard</a> <br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the code below will render a link for you to view your model in the Arthur Dashboard\n",
    "\n",
    "def render_arthur_model_dashboard_link(arthur, arthur_model):\n",
    "    url = 'https://' + ''.join(arthur.client.api_base_url.split('/')[1:-2])\n",
    "    link_text = f\"See your model ({arthur_model.display_name}) in the Arthur Dashboard\"\n",
    "    href_string = f\"{url}/model/{arthur_model.id}/overview\"\n",
    "    html_string = f'<br> <a style=\"font-size:200%\" href={href_string}>{link_text}</a> <br>'\n",
    "    display(HTML(html_string))\n",
    "\n",
    "render_arthur_model_dashboard_link(arthur, arthur_model_chatgpt) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cb3132",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once your inference data has been uploaded to the platform, you can see your model by following the above link to the model dashboard page to see an overview of the model and browse its inference data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096714d1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
