{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daa50e28",
   "metadata": {},
   "source": [
    "# Computer Vision Object Detection Yolo\n",
    "\n",
    "This notebook contains example code for onboarding an object detection model with Arthur. The model used is a pre-trained yolo object detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eedbe95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:28:57.516553Z",
     "start_time": "2021-09-09T15:28:42.708075Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import uuid\n",
    "import boto3\n",
    "import zipfile\n",
    "import sys\n",
    "import random\n",
    "import json\n",
    "%matplotlib inline\n",
    "\n",
    "# arthur imports\n",
    "from arthurai import ArthurAI\n",
    "from arthurai.common.constants import InputType, OutputType, Stage, ValueType, Enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0009a50",
   "metadata": {},
   "source": [
    "**Notes:** \n",
    "- This model is based on an implementation of YOLO model by @experiencor (https://github.com/experiencor/keras-yolo3).\n",
    "- Training and validation data is sourced from the VOC2012 database (http://host.robots.ox.ac.uk/pascal/VOC/voc2012/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d010db9",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Download images, and load meta data.\n",
    "\n",
    "### Bounding Box Format\n",
    "\n",
    "The meta data for training and validation sets bounding boxes preformatted in the way that Arthur expects to receive data.\n",
    "\n",
    "Arthur expects that bounding boxes are lists with the following elements:\n",
    "`[class_id, confidence, top_left_x, top_left_y, width, height]`\n",
    "\n",
    "See contents of DataFrames below for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c724e5e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:29:30.123572Z",
     "start_time": "2021-09-09T15:29:20.390530Z"
    }
   },
   "outputs": [],
   "source": [
    "# download images and trained model\n",
    "# this may take a couple minutes\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "s3.download_file('s3-bucket-arthur-public', 'sandbox/cv_object_detection_yolo/train.zip', 'data/train.zip')\n",
    "s3.download_file('s3-bucket-arthur-public', 'sandbox/cv_object_detection_yolo/val.zip', 'data/val.zip')\n",
    "s3.download_file('s3-bucket-arthur-public', 'sandbox/cv_object_detection_yolo/yolo_voc.h5', 'model/yolo_voc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca88283",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:29:31.126209Z",
     "start_time": "2021-09-09T15:29:30.125659Z"
    }
   },
   "outputs": [],
   "source": [
    "# extract images\n",
    "with zipfile.ZipFile('data/train.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data/')\n",
    "with zipfile.ZipFile('data/val.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed7f32b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:29:31.174786Z",
     "start_time": "2021-09-09T15:29:31.127983Z"
    }
   },
   "outputs": [],
   "source": [
    "# load training metadata\n",
    "# includes ground truth and predictions\n",
    "train_df = pd.read_csv('data/train_meta.csv')\n",
    "train_df['label'] = train_df['label'].apply(lambda x: json.loads(x))  # lists load a strings, convert\n",
    "train_df['objects_detected'] = train_df['objects_detected'].apply(lambda x: json.loads(x))  # lists load a strings, convert\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f155968f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:29:31.195351Z",
     "start_time": "2021-09-09T15:29:31.176882Z"
    }
   },
   "outputs": [],
   "source": [
    "# load validation metadata\n",
    "# includes only ground truth\n",
    "val_df = pd.read_csv('data/val_meta.csv')\n",
    "val_df['label'] = val_df['label'].apply(lambda x: json.loads(x)) # lists load as strings, convert\n",
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b78ee1",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "We have a pretrained model stored under `model` directory. `model/entrypoint.py` handles loading the model, as well as helper function for generating predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b261ac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:29:32.917395Z",
     "start_time": "2021-09-09T15:29:31.197731Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('model')\n",
    "from model.entrypoint import predict, class_labels, draw_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5516fb70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:29:33.151837Z",
     "start_time": "2021-09-09T15:29:32.919015Z"
    }
   },
   "outputs": [],
   "source": [
    "# load sample image\n",
    "sample = train_df.loc[100]\n",
    "sample_image = cv2.imread(sample['image'])\n",
    "\n",
    "# show sample image\n",
    "plt.imshow(np.flip(sample_image, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24905e26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:29:33.348952Z",
     "start_time": "2021-09-09T15:29:33.154370Z"
    }
   },
   "outputs": [],
   "source": [
    "# load ground truth\n",
    "gt = sample['label']\n",
    "annot_image = draw_boxes(sample_image, gt)\n",
    "\n",
    "# show annotated image\n",
    "plt.imshow(np.flip(annot_image, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f35a56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:29:34.807607Z",
     "start_time": "2021-09-09T15:29:33.353389Z"
    }
   },
   "outputs": [],
   "source": [
    "# make prediction\n",
    "predictions = predict(sample_image)\n",
    "annot_image = draw_boxes(sample_image, predictions)\n",
    "\n",
    "# show annotated image\n",
    "plt.imshow(np.flip(annot_image, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1f86c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:29:34.812338Z",
     "start_time": "2021-09-09T15:29:34.809189Z"
    }
   },
   "outputs": [],
   "source": [
    "# predictions returned in list of lists, how Arthur expects to receive bounding box data\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaffcc5",
   "metadata": {},
   "source": [
    "## Onboard Model to Arthur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25349fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T17:41:06.932695Z",
     "start_time": "2021-08-05T17:41:06.525885Z"
    }
   },
   "outputs": [],
   "source": [
    "# credentials are being passed to the client via environment variables\n",
    "connection = ArthurAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee866c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T17:41:07.251048Z",
     "start_time": "2021-08-05T17:41:07.217042Z"
    }
   },
   "outputs": [],
   "source": [
    "# define model metadata\n",
    "model_meta = {\n",
    "    \"partner_model_id\": f\"YOLO_ObjectDetection_QS-{datetime.now().strftime('%Y%m%d%H%M%S')}\",\n",
    "    \"display_name\": \"YOLO Object Detection\",\n",
    "    \"input_type\": InputType.Image,\n",
    "    \"output_type\": OutputType.ObjectDetection,\n",
    "    \"pixel_width\": 500,\n",
    "    \"pixel_height\": 375\n",
    "}\n",
    "model = connection.model(**model_meta)\n",
    "\n",
    "model.add_image_attribute(\"image\")\n",
    "\n",
    "predicted_attribute_name = \"objects_detected\"\n",
    "ground_truth_attribute_name = \"label\"\n",
    "model.add_object_detection_output_attributes(\n",
    "    predicted_attribute_name, \n",
    "    ground_truth_attribute_name, \n",
    "    class_labels)\n",
    "\n",
    "model.review()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c05ade9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T17:41:15.420807Z",
     "start_time": "2021-08-05T17:41:13.231326Z"
    }
   },
   "outputs": [],
   "source": [
    "model_id = model.save()\n",
    "with open(\"quickstart_model_id.txt\", \"w\") as f:\n",
    "    f.write(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09b2272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can fetch a model by ID. for example pull the last-created model:\n",
    "# with open(\"quickstart_model_id.txt\", \"r\") as f:\n",
    "#     model_id = f.read()\n",
    "# model = connection.get_model(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190a3489",
   "metadata": {},
   "source": [
    "## Set Reference Data\n",
    "\n",
    "In order to calculate data drift, Arthur requires uploading a reference data set. This is typically the dataset used for training the model.\n",
    "\n",
    "Any inference logged will then be compared against this reference dataset to determine its drift score.\n",
    "\n",
    "Reference data should be a dataframe, with columns for all the model attributes. In this case it is the single `PIPELINE_INPUT` attribute, `image`, as well as the predictions and labels, `objects_detected` and `label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2a17dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T17:42:56.251759Z",
     "start_time": "2021-08-05T17:41:21.645465Z"
    }
   },
   "outputs": [],
   "source": [
    "# use training data to \n",
    "model.set_reference_data(data=train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab588dc1",
   "metadata": {},
   "source": [
    "## Send Inferences\n",
    "\n",
    "We will now generarate predictions from the validation set, and log the predictions with Arthur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488b360a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T19:05:56.957245Z",
     "start_time": "2021-08-05T19:05:54.258153Z"
    }
   },
   "outputs": [],
   "source": [
    "num_to_send = 10\n",
    "\n",
    "inference_df = val_df.sample(num_to_send)\n",
    "inference_df['objects_detected'] = inference_df['image'].apply(lambda x: predict(cv2.imread(x)))\n",
    "inference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53539a39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T19:06:01.527068Z",
     "start_time": "2021-08-05T19:06:00.100547Z"
    }
   },
   "outputs": [],
   "source": [
    "# send inferences to arthur\n",
    "import pytz\n",
    "model.send_inferences(inference_df, inference_timestamps=[datetime(2021, 8, 5, tzinfo=pytz.utc) for _ in range(10)])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4d39c5bbfc27a9382ff3939c27278c2155cc9cf9db955121ed2eb56266ff7fd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
